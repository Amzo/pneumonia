{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of modelCNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfKWvoZkAo_6"
      },
      "source": [
        "Import our essential Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG7rSodLIfxn"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, Input, Activation\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htMf_OM36V8Q"
      },
      "source": [
        "Mount your google drive so that the dataset can be cloned to it from the git."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa16X9K30vzd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GeonvJs6c_S"
      },
      "source": [
        "Some shell script to check if the data already exists, if not clone it from git.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Spt-nH09kc"
      },
      "source": [
        "!if [ ! -d '/content/gdrive/MyDrive/pneumoniaDataset' ]; then mkdir '/content/gdrive/MyDrive/pneumoniaDataset'; fi\n",
        "\n",
        "\n",
        "!if [ ! -d '/content/gdrive/MyDrive/pneumoniaDataset/.git' ]; then git clone \"https://github.com/Amzo/xray_images\" '/content/gdrive/MyDrive/pneumoniaDataset/'; fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBBFNcZTIhNH"
      },
      "source": [
        "Load our data and generate additional augmented data due to the nature of the small data set. Since the data is already structured into train, test and validate folders, we don't need to split the data here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVNUu9ZmIs_n"
      },
      "source": [
        "def getData(trainDir, testDir, valDir):\n",
        "        class_names = os.listdir(trainDir)\n",
        "        class_types = len(os.listdir(trainDir))\n",
        "\n",
        "        print('Number of classes for Classification: ',class_types)\n",
        "        print(f'The class names are {class_names[0]} and {class_names[1]}')\n",
        "        print('--> Count of Train Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(trainDir + \"/\" +i))))\n",
        "        print('--> Count of Test Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(testDir + '/' +i))))\n",
        "\n",
        "        print('--> Count of Validation Images <---')\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(valDir + '/' +i))))\n",
        "\n",
        "        train_datagen = ImageDataGenerator(\n",
        "                rescale=1/255.0,\n",
        "                rotation_range=7,\n",
        "                width_shift_range=0.5,\n",
        "                height_shift_range=0.45,\n",
        "                shear_range=0.2,\n",
        "                zoom_range=0.45,\n",
        "                horizontal_flip=True\n",
        "        )\n",
        "\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "        xTrainGen = train_datagen.flow_from_directory(\n",
        "                trainDir,\n",
        "                target_size=(224,224),\n",
        "                shuffle=True,\n",
        "                batch_size=24,\n",
        "                class_mode='binary'\n",
        "        )\n",
        "\n",
        "        xTestGen = test_datagen.flow_from_directory(\n",
        "                testDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=16,\n",
        "                shuffle=True,\n",
        "                class_mode='binary'\n",
        "        )\n",
        "\n",
        "        xValGen = train_datagen.flow_from_directory(\n",
        "                valDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=32,\n",
        "                class_mode='binary'\n",
        "        )\n",
        "\n",
        "        return xTrainGen, xTestGen, xValGen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAxXDWXii2e-"
      },
      "source": [
        "def myModel():\n",
        "  print(\"Defaulting to basic CNN\")\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224,224,3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.6))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.7))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6cUN-KwBIA4"
      },
      "source": [
        "Create an Exception model. This model needs a lot of resources and will not run on my system.\n",
        "\n",
        "Using RMSprop optimiser and setting a learning rate to 0.0001. As our classification is either true or false, E.G they have something or they don't, use binary_crossentropy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB4tKR7-IzTY"
      },
      "source": [
        "def modelBuild(inputShape, modelType):\n",
        "  model = Sequential()\n",
        "  if (modelType == \"xception\"):\n",
        "    print(\"Setting up xception model\")\n",
        "    xception = Xception(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(xception)\n",
        "\n",
        "  elif (modelType == \"resnet\"):\n",
        "    print(\"Setting up resnet50 model\")\n",
        "    resnet = ResNet50V2(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(resnet)\n",
        "\n",
        "  elif (modelType == \"vgg16\"):\n",
        "    print(\"Setting up vgg16 model\")\n",
        "    vgg = VGG16(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(vgg)\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DkFgq_jJZoo"
      },
      "source": [
        "def modelTrain(model, xTrain, xVal, batchSize):\n",
        "  model.fit(xTrain,\n",
        "    epochs=10,\n",
        "    validation_data=xVal,\n",
        "    verbose=1,\n",
        "    batch_size=batchSize\n",
        "  )\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVccqMPJuE5"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "\n",
        "\n",
        "inputTrain = '/content/gdrive/MyDrive/pneumoniaDataset/train'\n",
        "inputTest = '/content/gdrive/MyDrive/pneumoniaDataset/test'\n",
        "inputValidate = '/content/gdrive/MyDrive/pneumoniaDataset/val'\n",
        "imageSize = (224,224,3)\n",
        "\n",
        "xTrain, xTest, xVal = getData(inputTrain, inputTest, inputValidate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaCaLFPwWeC4"
      },
      "source": [
        "xception = modelBuild(imageSize, 'xception')\n",
        "vgg16 = modelBuild(imageSize, 'vgg16')\n",
        "resnet = modelBuild(imageSize, 'resnet')\n",
        "myCNN = myModel()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVv-d5DQW66n"
      },
      "source": [
        "trainedVGG = modelTrain(vgg16, xTrain, xVal, 32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNKvW-xEdfze"
      },
      "source": [
        "trainedResnet = modelTrain(resnet, xTrain, xVal, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rZf1FgsjtZH"
      },
      "source": [
        "trainedCNN = modelTrain(myCNN, xTrain, xVal, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qH-s05GW6Q"
      },
      "source": [
        "trainedXception = modelTrain(xception, xTrain, xVal, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkVU2VqwgLiZ"
      },
      "source": [
        "print(\"Running Xception model against test set\")\n",
        "ev = trainedXception.evaluate(xTest)\n",
        "print(\"\\n%s: %.f%%\" % (trainedXception.metrics_names[1], ev[1]*100))\n",
        "print(\"Running VGG16 model against test set\")\n",
        "ev = trainedVGG.evaluate(xTest)\n",
        "print(\"\\n%s: %.f%%\" % (trainedVGG.metrics_names[1], ev[1]*100))\n",
        "print(\"Running resnet model against test set\")\n",
        "ev = trainedResnet.evaluate(xTest)\n",
        "print(\"\\n%s: %.f%%\" % (trainedResnet.metrics_names[1], ev[1]*100))\n",
        "print(\"Running myCNN model against test set\")\n",
        "ev = trainedCNN.evaluate(xTest)\n",
        "print(\"\\n%s: %.f%%\" % (trainedCNN.metrics_names[1], ev[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H7hw9ONlDBY"
      },
      "source": [
        "trainedXception.save('/content/drive/MyDrive/inception')\n",
        "trainedVGG.save('/content/drive/MyDrive/VGG')\n",
        "trainedResnet.save('/content/drive/MyDrive/Resnet')\n",
        "trainedCNN.save('/content/drive/MyDrive/myCNN')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}