{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelCNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RNOwytpsTnf"
      },
      "source": [
        "\n",
        "\n",
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxNsL-YjsXCX"
      },
      "source": [
        "Is this notebook there is the option to either train or load 4 additional models ontop of our model that we have created. These models where to compare their accuracy to our models accuracy and to also experiment with ensembling to see how the accuracy improved, which can be tested in the ensembling section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DOLUJWcsxmV"
      },
      "source": [
        "For the sake of speed, the training of the models can be skipped and the pretrained version can be fetched to save a substantial amount of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh3RClj9_Bf3"
      },
      "source": [
        "# Import Libraries (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfKWvoZkAo_6"
      },
      "source": [
        "Import our essential Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG7rSodLIfxn"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Input, Average\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.vgg19 import VGG19"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWubS2Xl_FsF"
      },
      "source": [
        "# Fetch Dataset (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GeonvJs6c_S"
      },
      "source": [
        "Some shell script to check if the data already exists, if not clone it from git.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Spt-nH09kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a414a331-74f4-41e9-c218-f902cfc492fd"
      },
      "source": [
        "%%shell\n",
        "\n",
        "if [ ! -d '/tmp/pneumoniaDataset' ]; then \n",
        "  mkdir '/tmp/pneumoniaDataset'\n",
        "fi\n",
        "\n",
        "if [ ! -d '/tmp/pneumoniaDataset/.git' ]; then \n",
        "  git clone \"https://github.com/Amzo/xray_images\" '/tmp/pneumoniaDataset/'\n",
        "fi"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqnKkQF7pVJF"
      },
      "source": [
        "dataIsFetched = True"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edyvCsH3_WwQ"
      },
      "source": [
        "# Datasetup (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBBFNcZTIhNH"
      },
      "source": [
        "Load our data and generate additional augmented data due to the nature of the small data set. Since the data is already structured into train, test and validate folders, we don't need to split the data here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVNUu9ZmIs_n"
      },
      "source": [
        "def getData(trainDir, testDir, valDir):\n",
        "        class_names = os.listdir(trainDir)\n",
        "        class_types = len(os.listdir(trainDir))\n",
        "\n",
        "        print('Number of classes for Classification: ',class_types)\n",
        "        print(f'The class names are {class_names[0]} and {class_names[1]}')\n",
        "        print('--> Count of Train Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(trainDir + \"/\" +i))))\n",
        "        print('--> Count of Test Images <--')\n",
        "\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(testDir + '/' +i))))\n",
        "\n",
        "        print('--> Count of Validation Images <---')\n",
        "        for i in class_names:\n",
        "                print(i + ':' + str(len(os.listdir(valDir + '/' +i))))\n",
        "\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255.0,\n",
        "                rotation_range=6,\n",
        "                zoom_range=0.1,\n",
        "                horizontal_flip = True,\n",
        "                vertical_flip = True\n",
        "                )\n",
        "\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255.0)\n",
        "\n",
        "        xTrainGen = train_datagen.flow_from_directory(\n",
        "                trainDir,\n",
        "                target_size=(224,224),\n",
        "                shuffle=True,\n",
        "                batch_size=24,\n",
        "                class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        xTestGen = test_datagen.flow_from_directory(\n",
        "                testDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=16,\n",
        "                shuffle=True,\n",
        "                class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        xValGen = train_datagen.flow_from_directory(\n",
        "                valDir,\n",
        "                target_size=(224,224),\n",
        "                batch_size=32,\n",
        "                class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        return xTrainGen, xTestGen, xValGen"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVccqMPJuE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53f5229-9a61-4012-cc23-e2cc34db4e26"
      },
      "source": [
        "try:\n",
        "  dataIsFetched\n",
        "except NameError:\n",
        "  print(\"Data has not been fetched, run the fetch data cells\")\n",
        "else:\n",
        "  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "  assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "\n",
        "\n",
        "  inputTrain = '/tmp/pneumoniaDataset/train'\n",
        "  inputTest = '/tmp/pneumoniaDataset/test'\n",
        "  inputValidate = '/tmp/pneumoniaDataset/val'\n",
        "\n",
        "  imageSize = (224,224,3)\n",
        "\n",
        "  xTrain, xTest, xVal = getData(inputTrain, inputTest, inputValidate)\n",
        "\n",
        "  dataIsSetup = True\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes for Classification:  2\n",
            "The class names are PNEUMONIA and NORMAL\n",
            "--> Count of Train Images <--\n",
            "PNEUMONIA:3851\n",
            "NORMAL:1305\n",
            "--> Count of Test Images <--\n",
            "PNEUMONIA:390\n",
            "NORMAL:234\n",
            "--> Count of Validation Images <---\n",
            "PNEUMONIA:32\n",
            "NORMAL:44\n",
            "Found 5156 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Found 76 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhCmy4Xj_mgB"
      },
      "source": [
        "# Data Visualisation (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IytTvLg7_qAp"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FiQHMJa_ubx"
      },
      "source": [
        "try:\n",
        "  dataIsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the dataSetup section before training\")\n",
        "else:\n",
        "  augmentedImages = [xTrain[0][0][0] for i in range(5)]"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G79arOf5_vLy"
      },
      "source": [
        "plotImages(augmentedImages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw27h6HZAbDE"
      },
      "source": [
        "# Model Setup (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAxXDWXii2e-"
      },
      "source": [
        "def myModel():\n",
        "  print(\"Defaulting to basic CNN\")\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(224,224,3)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6cUN-KwBIA4"
      },
      "source": [
        "Create an Exception model. This model needs a lot of resources and will not run on my system.\n",
        "\n",
        "Using RMSprop optimiser and setting a learning rate to 0.0001. As our classification is either true or false, E.G they have something or they don't, use binary_crossentropy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB4tKR7-IzTY"
      },
      "source": [
        "def modelBuild(inputShape, modelType):\n",
        "  model = Sequential()\n",
        "  if (modelType == \"xception\"):\n",
        "    print(\"Setting up xception model\")\n",
        "    xception = Xception(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(xception)\n",
        "\n",
        "  elif (modelType == \"resnet\"):\n",
        "    print(\"Setting up resnet50 model\")\n",
        "    resnet = ResNet50V2(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(resnet)\n",
        "\n",
        "  elif (modelType == \"vgg19\"):\n",
        "    print(\"Setting up vgg19 model\")\n",
        "    vgg = VGG19(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(vgg)\n",
        "  elif (modelType == \"inception\"):\n",
        "    print(\"Setting up inception model\")\n",
        "    inception = InceptionV3(include_top=False,\n",
        "      weights= 'imagenet',\n",
        "      input_shape=inputShape,\n",
        "    )\n",
        "    model.add(inception)\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(Dense(2,activation=\"softmax\"))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaCaLFPwWeC4"
      },
      "source": [
        "xception = modelBuild(imageSize, 'xception')\n",
        "vgg19 = modelBuild(imageSize, 'vgg19')\n",
        "resnet = modelBuild(imageSize, 'resnet')\n",
        "inception = modelBuild(imageSize, 'inception')\n",
        "myCNN = myModel()\n",
        "\n",
        "modelsSetup = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Ch1zUlI90P"
      },
      "source": [
        "# Train Models (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DkFgq_jJZoo"
      },
      "source": [
        "def modelTrain(model, xTrain, xVal, batchSize):\n",
        "  history = model.fit(xTrain,\n",
        "    epochs=10,\n",
        "    validation_data=xVal,\n",
        "    verbose=1,\n",
        "    batch_size=batchSize\n",
        "  )\n",
        "\n",
        "  modelsAreTrained = True\n",
        "  return history, model\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJScHMVXNNsQ"
      },
      "source": [
        "I could create a function to check if the models have been setup, but you can never be certain if a cell has been executed or not, so rely on global variables being true or false. This means duplication, but it's should reduce errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShyxwhvuFfIr"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  inceptionHistoy, trainedInception = modelTrain(inception, xTrain, xVal, 32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVv-d5DQW66n"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  vggHistory, trainedVGG = modelTrain(vgg19, xTrain, xVal, 32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNKvW-xEdfze"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  resnetHistory, trainedResnet = modelTrain(resnet, xTrain, xVal, 32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rZf1FgsjtZH"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  ourCNNHistory, trainedCNN = modelTrain(myCNN, xTrain, xVal, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qH-s05GW6Q"
      },
      "source": [
        "try:\n",
        "  modelsSetup\n",
        "except NameError:\n",
        "  print(\"please execute the model Setup section before training\")\n",
        "else:\n",
        "  xceptionHistory, trainedXception = modelTrain(xception, xTrain, xVal, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTafmHjGPelh"
      },
      "source": [
        "# Save Trained Models (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJ0NoZgQEWO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H7hw9ONlDBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1c9034-8fed-43c4-f66f-43eee65ceced"
      },
      "source": [
        "try:\n",
        "  inceptionHistory.History\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the Inception model to save?\")\n",
        "else:\n",
        "  trainedInception.save('/content/gdrive/MyDrive/Inception')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/inceptionHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(inceptionHistoy.history, outFile)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Have you trained the Inception model to save?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT_ErbE4Pi_h",
        "outputId": "f09d2a34-efb9-4890-fea7-6f449667d0b7"
      },
      "source": [
        "try:\n",
        "  vggHistory.history\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the VGG model to save?\")\n",
        "else:\n",
        "  trainedVGG.save('/content/gdrive/MyDrive/VGG')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/vggHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(vggHistory.history, outFile)\n",
        "  "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Have you trained the VGG model to save?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tK-y-0gPuI6",
        "outputId": "08bf58b8-461f-42f0-e669-f32228645afd"
      },
      "source": [
        "try:\n",
        "  resnetHistory.History\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the resnet model to save?\")\n",
        "else:\n",
        "  trainedResnet.save('/content/gdrive/MyDrive/Resnet')\n",
        "  \n",
        "  with open('/content/gdrive/MyDrive/resnetHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(resnetHistory.history, outFile)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Have you trained the resnet model to save?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLchU53DP8Js",
        "outputId": "dde08463-93d4-4b9b-c2bb-411ed8d8fdd4"
      },
      "source": [
        "try:\n",
        "  ourCNNHistory.history\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained myCNN model to save?\")\n",
        "else:\n",
        "  trainedCNN.save('/content/gdrive/MyDrive/myCNN')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/ourCNNHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(ourCNNHistory.history, outFile)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Have you trained myCNN model to save?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfktWugYPRSu",
        "outputId": "cbbe6ca4-79ea-490e-f922-9f7ebec7f8ca"
      },
      "source": [
        "try:\n",
        "  xceptionHistory.history\n",
        "except (AttributeError, NameError):\n",
        "  print(\"Have you trained the Xception model to save?\")\n",
        "else:\n",
        "  trainedXception.save('/content/gdrive/MyDrive/xception')\n",
        "\n",
        "  with open('/content/gdrive/MyDrive/xceptionHistory.pickle', 'wb') as outFile:\n",
        "    pickle.dump(xceptionHistory.history, outFile)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Have you trained the Xception model to save?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPXRjxElvAUN"
      },
      "source": [
        "# Fetch Trained Models (Required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpr86FHc5yOh"
      },
      "source": [
        "This shell script will fetch all the models and history from my one drive so that it can be loaded. Will save an hour or two over waiting for training to finish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc4--Bgm5nwH"
      },
      "source": [
        "Shell variables don't appear to be reusable from other cells, so perform all the shell script in one cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf8UQEGfvMTN",
        "outputId": "611ab3f4-1a4c-4885-dda1-9bd922610aa4"
      },
      "source": [
        "%%shell\n",
        "function extractModel() {\n",
        "  outDIR=\"/tmp/trainedModels/\"\n",
        "\n",
        "  # check if the directory exits, if not create it\n",
        "  if [ ! -d $outDIR ]; then \n",
        "    mkdir -p $outDIR; \n",
        "  fi\n",
        "\n",
        "  # extract the model\n",
        "  echo \"extracting ${1} to ${outDIR}\"\n",
        "  unzip -q -o -d $outDIR $1 \n",
        "}\n",
        "\n",
        "function getFile() {\n",
        "  googleURL=\"https://docs.google.com/uc?export=download\"\n",
        "  echo \"fetching file: ${2}\"\n",
        "  wgetCMD=\"wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate\"\n",
        "  fileID=\"$1\"\n",
        "  outFILE=\"/tmp/$2\"\n",
        "\n",
        "  if [ -f $outFILE ]; then\n",
        "    rm -f $outFILE\n",
        "  fi\n",
        "  \n",
        "  wget  -q --load-cookies /tmp/cookies.txt \"$googleURL&confirm=$($wgetCMD \"$googleURL&id=$fileID\" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$fileID\" -O $outFILE\n",
        "  rm -rf /tmp/cookies.txt\n",
        "  \n",
        "  if [ ${outFILE##*.} == \"zip\" ]; then\n",
        "    extractModel $outFILE\n",
        "  fi\n",
        "}\n",
        "\n",
        "# inception model\n",
        "getFile \"185GypHJV8sTcL3siYXinoClbXP0OEYr1\" \"trainedInception.zip\"\n",
        "\n",
        "# inception history\n",
        "getFile \"1kqAMFgH5H-_k1cKYuuatSuZiG-xtajh_\" \"inceptionHistory.pickle\"\n",
        "\n",
        "# vgg model\n",
        "getFile \"163-EY3aU6_7OP0Ds2Gq4bIu9r84f4txJ\" \"trainedVgg.zip\"\n",
        "\n",
        "# vgg history\n",
        "getFile \"1-0H4ZjHitt8FMC1ZjZun1wlXrFMjFE5N\" \"vggHistory.pickle\"\n",
        "\n",
        "# resnet model\n",
        "getFile \"1E4pHn5-4-9VXDIdlk9qFZya1TjL_u3P-\" \"trainedResnet.zip\"\n",
        "\n",
        "# resnet history\n",
        "getFile \"1-0nN6H7lMCNPD4tlS_CXD1JMEXPcFnc9\" \"resnetHistory.pickle\"\n",
        "\n",
        "# myCNN model\n",
        "getFile \"16Ko5GLm4D3jz6F7s85FkoqCDrI4vUeiV\" \"trainedCNN.zip\"\n",
        "\n",
        "# myCNN history\n",
        "getFile \"1-BFAv4_m3fwlYLgWCWbziSQPplKlGfvQ\" \"ourCNNHistory.pickle\"\n",
        "\n",
        "# xception model\n",
        "getFile \"1qqRKAyN5lowZ3VE8cQZWBU54eP-QA9q-\" \"trainedXception.zip\"\n",
        "\n",
        "# xception history\n",
        "getFile \"1-HHmEafOoAMlYXngAS8sjagA-Evlc3n9\" \"xceptionHistory.pickle\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fetching file: trainedInception.zip\n",
            "extracting /tmp/trainedInception.zip to /tmp/trainedModels/\n",
            "fetching file: inceptionHistory.pickle\n",
            "fetching file: trainedVgg.zip\n",
            "extracting /tmp/trainedVgg.zip to /tmp/trainedModels/\n",
            "fetching file: vggHistory.pickle\n",
            "fetching file: trainedResnet.zip\n",
            "extracting /tmp/trainedResnet.zip to /tmp/trainedModels/\n",
            "fetching file: resnetHistory.pickle\n",
            "fetching file: trainedCNN.zip\n",
            "extracting /tmp/trainedCNN.zip to /tmp/trainedModels/\n",
            "fetching file: ourCNNHistory.pickle\n",
            "fetching file: trainedXception.zip\n",
            "extracting /tmp/trainedXception.zip to /tmp/trainedModels/\n",
            "fetching file: xceptionHistory.pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twWwJ9AY6_SY"
      },
      "source": [
        "modelsAreFetched = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yst13qUP7EpW"
      },
      "source": [
        "# Load Models (Required)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N48GiZSj7HY6"
      },
      "source": [
        "historyList = [\"inceptionHistory\", \"vggHistory\", \"resnetHistory\", \"ourCNNHistory\", \"xceptionHistory\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5hAZTnh7gHO"
      },
      "source": [
        "modelList = [\"Inception\", \"Resnet\", \"VGG\", \"myCNN\", \"xception\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COQ3DIEn7rfI",
        "outputId": "ffbc46e6-1641-44a9-94af-44d738f60fa1"
      },
      "source": [
        "try:\n",
        "  modelsAreFetched\n",
        "except NameError:\n",
        "  print(\"You need to fetch the models to load them\")\n",
        "else:\n",
        "  for pickleFile in historyList:\n",
        "    with open('/tmp/' + pickleFile + '.pickle', 'rb') as input:\n",
        "      if (pickleFile == \"inceptionHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        inceptionHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"resnetHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        resnetHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"vggHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        vggHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"ourCNNHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        myCNNHistory = pickle.load(input)\n",
        "      elif (pickleFile == \"xceptionHistory\"):\n",
        "        print(\"Loading history file: \" + pickleFile)\n",
        "        xceptionHistory = pickle.load(input)\n",
        "\n",
        "      historyIsFetched = True"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading history file: inceptionHistory\n",
            "Loading history file: vggHistory\n",
            "Loading history file: resnetHistory\n",
            "Loading history file: ourCNNHistory\n",
            "Loading history file: xceptionHistory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ0JdTHy8_q0",
        "outputId": "ed84ab3f-62a2-4a38-c034-c41c2ff53a57"
      },
      "source": [
        "try:\n",
        "  modelsAreFetched\n",
        "except NameError:\n",
        "  print(\"You have to fetch the models before you can load them\")\n",
        "else:\n",
        "  for trainedModel in modelList:\n",
        "    print(\"Loading model \" + trainedModel)\n",
        "    if (trainedModel == \"Inception\"):\n",
        "      trainedInception = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"Resnet\"):\n",
        "      trainedResnet = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"VGG\"):\n",
        "      trainedVGG = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"myCNN\"):\n",
        "      trainedCNN = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)\n",
        "    elif (trainedModel == \"xception\"):\n",
        "      trainedXception = tf.keras.models.load_model('/tmp/trainedModels/' + trainedModel)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model Inception\n",
            "Loading model Resnet\n",
            "Loading model VGG\n",
            "Loading model myCNN\n",
            "Loading model xception\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj1yHyb6JCYF"
      },
      "source": [
        "# Test Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmy7LbYNnY2q"
      },
      "source": [
        "def evaluateModel(model):\n",
        "  ev = model.evaluate(xTest)\n",
        "  print(\"\\n%s: %.f%%\" % (model.metrics_names[1], ev[1]*100))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkVU2VqwgLiZ"
      },
      "source": [
        "try:\n",
        "  dataIsSetup\n",
        "except NameError:\n",
        "  print(\"Please run datasetup cells first\")\n",
        "else:\n",
        "  for trainedModel in modelList:\n",
        "      print(\"Running \" + trainedModel + \" against test set\")\n",
        "      if (trainedModel == \"Inception\"):\n",
        "        evaluateModel(trainedInception)\n",
        "      elif (trainedModel == \"Resnet\"):\n",
        "        evaluateModel(trainedResnet)\n",
        "      elif (trainedModel == \"VGG\"):\n",
        "        evaluateModel(trainedVGG)\n",
        "      elif (trainedModel == \"myCNN\"):\n",
        "        evaluateModel(trainedCNN)\n",
        "      elif (trainedModel == \"xception\"):\n",
        "        evaluateModel(trainedXception)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKW_CwJXBVdJ"
      },
      "source": [
        "# Model History Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83txYOQHAwDW"
      },
      "source": [
        "def visualiseHistory(historyFile):\n",
        "  try:\n",
        "    plt.plot(historyFile.history['accuracy'], label='accuracy')\n",
        "    plt.plot(historyFile.history['val_accuracy'], label = 'val_accuracy')\n",
        "  except AttributeError:\n",
        "    plt.plot(historyFile['accuracy'], label='accuracy')\n",
        "    plt.plot(historyFile['val_accuracy'], label = 'val_accuracy')\n",
        "\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([0.5, 1])\n",
        "  plt.legend(loc='lower right')\n",
        "\n",
        "  test_loss, test_acc = trainedCNN.evaluate(xTest, verbose=2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNgIMgwbBW6m"
      },
      "source": [
        "def visualiseLoss(historyFile):\n",
        "  # summarize history for loss\n",
        "  try:\n",
        "    plt.plot(historyFile.history['loss'])\n",
        "    plt.plot(historyFile.history['val_loss'])\n",
        "  except AttributeError:\n",
        "    plt.plot(historyFile['loss'])\n",
        "    plt.plot(historyFile['val_loss'])\n",
        "\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_AWDLmoBs3P"
      },
      "source": [
        "visualiseHistory(inceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0nkXs4qB-YC"
      },
      "source": [
        "visualiseLoss(inceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiQhlP4eCP7t"
      },
      "source": [
        "visualiseHistory(vggHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZDWwiuDCsAS"
      },
      "source": [
        "visualiseLoss(vggHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woPIVez7CvCB"
      },
      "source": [
        "visualiseHistory(myCNNHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UdY38jECzdy"
      },
      "source": [
        "visualiseLoss(myCNNHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b2VRnQYC2LS"
      },
      "source": [
        "visualiseHistory(resnetHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbpZcs1aC4Py"
      },
      "source": [
        "visualiseLoss(resnetHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9APZSemC-Fw"
      },
      "source": [
        "visualiseHistory(xceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Jv8dSFDAlH"
      },
      "source": [
        "visualiseLoss(xceptionHistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VCGKVPnD7oZ"
      },
      "source": [
        "# Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-kPAA2yE21t"
      },
      "source": [
        "def getVoting():\n",
        "  models = list()\n",
        "  models.append(trainedInception)\n",
        "  models.append(trainedVGG)\n",
        "  models.append(trainedResnet)\n",
        "  models.append(trainedCNN)\n",
        "  models.append(trainedXception)\n",
        "\n",
        "  return models"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daY_7ikxFGDw"
      },
      "source": [
        "combinedModel = getVoting()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MdpWb4azOfa"
      },
      "source": [
        "modelInput = Input(shape=(224, 224, 3))\n",
        "modelOutputs = [model(modelInput) for model in combinedModel]\n",
        "ensembleOutput = Average()(modelOutputs)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-1kmCqiFVJB"
      },
      "source": [
        "ensembleModel = Model(inputs=modelInput, outputs=ensembleOutput, name='ensemble')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Px2C7e6rr0"
      },
      "source": [
        "ensembleModel.compile(optimizer='adam',\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXRgv5_K7dnk",
        "outputId": "165d56d5-9e9f-4dde-bd08-43c5a36ec815"
      },
      "source": [
        "print(\"Running ensembled model against test set\")\n",
        "evaluateModel(ensembleModel)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running ensembled model against test set\n",
            "39/39 [==============================] - 14s 233ms/step - loss: 0.2965 - accuracy: 0.9230\n",
            "\n",
            "accuracy: 93%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}